{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "appointed-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from fairseq.models.bart import BARTModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e459c6de-c22a-4077-a3f9-2570c12757c9",
   "metadata": {},
   "source": [
    "#### Load Annotated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59897d15-4735-4cd4-9dab-5becdc587ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = json.load(open('../data/train.json', 'r'))\n",
    "test_set = json.load(open('../data/test.json', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d2f8aa-755a-42f7-b5f9-4e262b6cf120",
   "metadata": {},
   "source": [
    "#### Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac01838a-e509-4b17-91ed-d50e7c4ead07",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMLM_MODEL_PATH = 'BART_models/xsum_cedar_cmlm'\n",
    "MLM_MODEL_PATH = 'BART_models/bart.large'\n",
    "\n",
    "DATA_NAME_OR_PATH = 'summarization/XSum/fairseq_files/xsum-bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assigned-exhibition",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 01:25:13 | INFO | fairseq.file_utils | loading archive file /home/mila/c/caomeng/scratch/BART_models/xsum_cedar_cmlm\n",
      "2022-04-07 01:25:13 | INFO | fairseq.file_utils | loading archive file /home/mila/c/caomeng/scratch/summarization/XSum/fairseq_files/xsum-bin\n",
      "2022-04-07 01:25:22 | INFO | fairseq.tasks.translation | [source] dictionary: 50264 types\n",
      "2022-04-07 01:25:22 | INFO | fairseq.tasks.translation | [target] dictionary: 50264 types\n"
     ]
    }
   ],
   "source": [
    "bart = BARTModel.from_pretrained(CMLM_MODEL_PATH,\n",
    "                                 checkpoint_file='checkpoint_best.pt',\n",
    "                                 data_name_or_path=DATA_NAME_OR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "elementary-dutch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 01:25:32 | INFO | fairseq.file_utils | loading archive file /home/mila/c/caomeng/scratch/BART_models/bart.large\n",
      "2022-04-07 01:25:32 | INFO | fairseq.file_utils | loading archive file /home/mila/c/caomeng/scratch/BART_models/bart.large\n",
      "2022-04-07 01:25:39 | INFO | fairseq.tasks.denoising | dictionary: 50264 types\n"
     ]
    }
   ],
   "source": [
    "prior_bart = BARTModel.from_pretrained(MLM_MODEL_PATH,\n",
    "                                       checkpoint_file='model.pt',\n",
    "                                       data_name_or_path=MLM_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-raise",
   "metadata": {},
   "source": [
    "#### Build Prior & Posterior Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "trained-township",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EntFA.model import ConditionalSequenceGenerator\n",
    "from EntFA.utils import prepare_cmlm_inputs, prepare_mlm_inputs, get_probability_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "varied-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConditionalSequenceGenerator(bart)\n",
    "prior_model = ConditionalSequenceGenerator(prior_bart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94283abf-8d88-4d55-b938-a8eafd86cc5f",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a100d3c-65ed-4c04-98d4-4bca7509887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7614572-dff0-428b-9550-e11727986f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(train_features, train_labels, n=30):\n",
    "    classifier = neighbors.KNeighborsClassifier(n_neighbors=30, algorithm='auto')\n",
    "    \n",
    "    x_mat = np.array(train_features)\n",
    "    stds = [np.std(x_mat[:, 0]), np.std(x_mat[:, 1]), np.std(x_mat[:, 2])]\n",
    "    x_mat = np.vstack([x_mat[:, 0]/stds[0],  x_mat[:, 1]/stds[1], x_mat[:, 2]/stds[2]]).transpose()\n",
    "    y_vec = np.array(train_labels)\n",
    "    classifier.fit(x_mat, y_vec)\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "def infernece(test_features, classifier):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        test_features (List[List]): [[prior, posterior, overlap_feature], ...]\n",
    "        classifier: KNN classifier\n",
    "    \"\"\"\n",
    "    x_mat = np.array(test_features)\n",
    "    stds = [np.std(x_mat[:, 0]), np.std(x_mat[:, 1]), np.std(x_mat[:, 2])]\n",
    "    x_mat = np.vstack([x_mat[:, 0]/stds[0],  x_mat[:, 1]/stds[1], x_mat[:, 2]/stds[2]]).transpose()\n",
    "    Z = classifier.predict(x_mat)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "618e8509-2e27-443a-bef0-b0f011873041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data_set, prior_model, model):\n",
    "    label_mapping = {\n",
    "        'Non-hallucinated': 0,\n",
    "        'Factual Hallucination': 0,\n",
    "        'Non-factual Hallucination': 1\n",
    "    }\n",
    "\n",
    "    features, labels = [], []\n",
    "    for t in tqdm(data_set):\n",
    "        source, prediction, entities = t['source'], t['prediction'], t['entities']\n",
    "\n",
    "        inputs = prepare_mlm_inputs(source, prediction, ent_parts=entities)\n",
    "        priors = get_probability_parallel(prior_model, inputs[0], inputs[1], inputs[2], inputs[3], mask_filling=True)\n",
    "\n",
    "        inputs = prepare_cmlm_inputs(source, prediction, ent_parts=entities)\n",
    "        posteriors = get_probability_parallel(model, inputs[0], inputs[1], inputs[2], inputs[3])\n",
    "\n",
    "        overlaps = [1. if e['ent'].lower() in source.lower() else 0. for e in entities]\n",
    "        assert len(priors) == len(posteriors) == len(overlaps)\n",
    "\n",
    "        for i, e in enumerate(entities):\n",
    "            if label_mapping.get(e['label'], -1) != -1:\n",
    "                features.append((priors[i], posteriors[i], overlaps[i]))\n",
    "                labels.append(label_mapping[e['label']])\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "904efb35-da2b-4c56-add4-e4e618722a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 460/460 [00:49<00:00,  9.22it/s]\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = get_features(train_set, prior_model, model)\n",
    "classifier = build_classifier(train_features, train_labels, n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77027fa-c1ca-4a42-a441-e60d70a3fbef",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a938bec0-738e-4321-a821-a01696256a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:25<00:00,  9.52it/s]\n"
     ]
    }
   ],
   "source": [
    "test_features, test_labels = get_features(test_set, prior_model, model)\n",
    "Z = infernece(test_features, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4b1d32c-fcab-4b0d-9128-f6d4cd1a1964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9102\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Factual     0.9323    0.9629    0.9474       701\n",
      " Non-Factual     0.7658    0.6343    0.6939       134\n",
      "\n",
      "    accuracy                         0.9102       835\n",
      "   macro avg     0.8490    0.7986    0.8206       835\n",
      "weighted avg     0.9056    0.9102    0.9067       835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: {:.4}\\n\\n'.format(accuracy_score(test_labels, Z)))\n",
    "print(classification_report(test_labels, Z, target_names=['Factual', 'Non-Factual'], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fe2f43-19bb-48b3-9bbe-b6b778cb802a",
   "metadata": {},
   "source": [
    "#### Save Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3747c5e-4175-493b-a395-6b7ab3d77d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(classifier, open('knn_classifier.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
